1. Fetch emails. Add them to pipeline (with a producer-consumer pattern)
2. Process emails -> (THINK ABOUT PARALLELISM - either asyncio loop for api call or batch request to OpenAi API)

    2.1. First, check if the email is already in the database (duplicates can happen), OR if it should be ignored (i.e. if it's a reply to an email that's already in the database)
        2.1.1   Check by email_id FIRST, THEN by email_subject or other small fields. If it's a duplicate, skip it.
        2.1.2   Think about how to ignore auto-replies, or spam, or stuff like delivery-has-failed emails

    2.2    If it's not a duplicate, then process it
        2.2.1   Extract the ship and cargo data from the email - via OpenAi API for now.
        2.2.2   Add the ship and cargo data to the database. If the ship or cargo already exists, then handle udpates.

3. Go over all ships without cargo pairs, and find the best cargo for each ship
    3.1. Find all cargoes that match the ship's criteria (i.e. port_from, port_to, sea_from, sea_to, month, quantity)
    3.2. Have some simple scoring system, and allocate the top 5-10 cargos to the ship
    3.3. Add the pairs to the database
    3.4. ADD SEND EMAIL TASK to the pipeline. Pass all necessary data to the task (i.e the MongoDB object(s))

4. Email sending consumer
    4.1. Constantly check the pipeline for new email sending tasks
    4.2. For each email, generate the email body and send it to the relevant email address. (i.e. the email address of the ship owner)
    4.3. Add references to the database for each email sent (figure out how to do this best)


Notes:
Think about how to allocate processing power - see if there are any bottlenecks, if so slow down the producer or consumer.
Eg. Too much is used on processing emails, so slow down the producer.

Think about how to handle errors - if an email fails to send, then what? Retry? Or just log it and move on?

Think about how to handle updates - if a ship or cargo is updated, then what? Do we need to update the pairs? Or just leave them as is?

Think about how to handle duplicates - if a ship or cargo is duplicated, then what? Do we need to update the pairs? Or just leave them as is?



Producer 1
1. Reads all UNSEEN emails from mailbox, setting them as read, and adding the relevant AdaptedEmailMessage object to the queue_read_emails_to_db_with_id queue for further processing.

mQ_1 = asyncio.Queue(maxsize=10)

Consumer 1
1. Takes out AdaptedEmailMessage objects from the queue_read_emails_to_db_with_id queue
2. Adds the relevant AdaptedEmailMessage object to the database, after checking all relevant fields to see if it already exists

Producer 2
1. Takes out email objects from the database (via Change Streams) and places them into MQ 2, from most recent and that have not yet been processed by the consumer 2

mQ_2 = asyncio.Queue(maxsize=10)

Consumer 2
1. Takes out email objects from MQ 2, and processes them via GPT-3.5
# IMPORTANT - include duplicate checker, on an object level too - and email might be different, but the ship or cargo might be the same. So check for duplicates on the object level too.
2. Adds the relevant entries to the database, after checking all relevant fields to see if it already exists

Endless process 1 - Match ships to cargos, and update DB state
1. Takes out Ships from database (Change Stream on Add To Ship?), that have no cargo pairs, and finds matching cargo for them. Update all relevant fields in the database.
Idea: Change Stream on new ship additions - and do the matching.

Producer 3 - Email ships that just got matched (Consumer 3)
Idea: Change Stream on Cargo Matches being added to a Ship - then add objects with all data to the Mail Sending queue (MQ3).

mq_3 = asyncio.Queue(maxsize=10)

Consumer 3
1. Takes out email objects from MQ 3, and sends them via email to the relevant email address (i.e. the ship owner's email address), ship and cargo objects.



improving matching algorithm

Define Matching Criteria:

Identify key parameters that define a good match. These could include capacity, port, sea, date, or other relevant attributes.
Consider the importance or weight of each criterion in the matching process.
Normalize Data:

Normalize data to ensure consistency and comparability. For example, standardize units, date formats, and other relevant attributes.
Scoring System:

Implement a scoring system to evaluate the similarity between a cargo and a ship based on the defined criteria.
Assign weights to different criteria based on their importance.
For each criterion, calculate a score that represents how well a cargo matches a ship.
Thresholds:

Set threshold values to filter out matches that fall below a certain score.
Consider different threshold levels for different criteria.
Use Database Querying:

Leverage database querying capabilities to filter cargos and ships based on the defined criteria.
Use MongoDB queries, as in your previous examples, to narrow down potential matches.
Geospatial Matching:

If relevant, consider geospatial matching for ports and seas. MongoDB supports geospatial queries that can help find cargos and ships within a certain geographical range.
Dynamic Matching:

Implement a dynamic matching system that adapts to changing conditions. For example, consider time-sensitive criteria and adjust the matching algorithm accordingly.
Feedback Loop:

Implement a feedback loop system to continuously improve the matching algorithm.
Collect feedback from users, track successful and unsuccessful matches, and use this information to refine the matching criteria and weights.
Asynchronous Matching:

Depending on the size of your dataset and the complexity of your matching algorithm, consider performing matching asynchronously to improve system responsiveness.
Testing and Validation:

Regularly test and validate your matching algorithm using a diverse set of test cases.
Consider A/B testing to compare the effectiveness of different matching strategies.
Machine Learning (Optional):

Depending on the complexity and variety of your matching criteria, consider machine learning techniques to automate and optimize the matching process.
Remember that the effectiveness of the matching system depends on the specific requirements and characteristics of your application. Adjust and refine your matching algorithm based on real-world performance and user feedback.


TODO:

1. Improve GPT entity extraction
    1.1 Add more fields via calculated fields - (QUANTITY) quantity_from, quantity_to. (PORT and SEA/LOCATIONS in general)...,
    1.2 Optimize prompts to be less tokens.

2. Improve DB add and fetch of objects
    2.1 Handle existing ships and cargos - update only if found comission is different or something ? or update the date?

3. Improve matching algorithm
    3.1 Consider more rules and think more deeply about them
    3.2 Consider non-negotiables and how to handle (i.e weight is out of range, or location is a miss-match)    

